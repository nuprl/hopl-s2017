# Title : Type Inference in Stack-Based Programming Languages
## Speaker : Rob Kleffner

The + operator is like a 位 followed by an implicit call

A 位 is technically applied to the whole stack, but a `k`-ary function pops
 exactly `k` arguments (and fails if the stack is too small)

(On semantics of 位)

> A: this is obvious
> B: obvious
> C: totally not obvious


### Polai, _Algebraic Specifications of Stack Effects_, Forth Dimensions 1990

Presents a type system that proves programs don't raise "empty stack"
exceptions.

Types are comments (in Forth), e.g.

```
  / : i1 i2 -- div rem
```

is the operator `/` followed by a comment that says it expects two inputs
(`i1` `i2`) and pushes two result values onto the stack (`div` `rem`)

"There's always a valid type derivation"

> M: can you prove this theorem?
> K: well the paper doesn't really state theorems
> M: Yes it does. Theorems are claims. Even nonsense papers are full of
>    theorems. The question is, do they hold? 

Forth doesn't actually have types, you just pop a word's worth of bits and
interpret them.


### Polai, _Multiple Stack Effects for Forth Programs_, Euro Forth 1991


### Stoddart and Knaggs, _Type Inference in Stack-Based Languages_, FAC 1992

> M: static type inference is typically posed as
>    - if I start with an explicitly typed program
>    - then remove all annotations
>    - can I restore the type annotations?
> K: yes that's what the paper is doing
> M: no, because the 'type inference' algorithm is injecting polymorphism
> T: you're upset because there's no syntactic slot to instantiate a function
>    with a type parameter?
> M: exactly

### Interlude: type inference vs. type reconstruction

Type Inference is about recovering types that were erased from an explicitly
typed program.

Type Reconstruction is about "figuring out types" for a given program.

Terminology is from CMU circa 1993.

> W: so type inference is basically 'partial type reconstruction', because
>    its domain is a subset of 'all given programs'
> M: sure

> A: so, a programmer can't make anything polymorphic?
> K: right, they cant


### HiForth (Higher-Order Forth)

> M: what does 位 do to make closures in a real stack-based language?
> K: Joy has only 0-ary functions, so it doesn't make closures
> M: is there a real, higher-order stack language
> K: maybe Kitten? but it's in development
> M: do you know how they do closures?
> K: the language is interpreted in Haskell, variables sit in memory
> D: in the heap? then it's not a stack language

- [kitten](http://kittenlang.org/)
- [joy](https://en.wikipedia.org/wiki/Joy_(programming_language))


### Okasaki, _Techniques for Embedding Post-Fix Languages in Haskell_, Haskell 2002

> M: I talked with Okasaki at the time, he got the problem from a Smullyan-style
>    puzzle --- "what if I erase all parentheses in an ??? program"

> W: Rob you said, 'people seemed satisfied' in the decade between the last
>    paper and Okasaki's. You mean 'people forgot'?
> K: ok, yeah

> T: do people program in a typed style in Forth?
> K: I believe Forth programmers use typing algorithms for static analysis,
>    but not to accept/reject programs (type errors = warnings?)

Okasaki's the first to make functions that are polymorphic over the stack size,
uses nested tuples to represent the type-level stack

Three techniques:

1. prefix embedding
2. `x # f1 # ... # fn` embedding
3. removes the hashes with higher-rank polymorphism

> W: any connection between this work and Danvy's DSL for typed `printf`?
> K: not sure, maybe


### Diggins, _Typed Functional Stack Based Languages_, Unpublished 2007

"simple" vs. "stack" type variables

> T: are we just solving a notation problem?
> M: I hate the word 'just'
> T: are we solving a notation problem?
> M: pop quiz, is it important to solve notation problems?
> ....
> M: Yes. It's the Laffer curve of type systems. Don't forget it.

function types in this system look like:

```
  f := a... \vec{b} -> a... \vec{b}
```

the dots are connected to the `a...`

if a function's domain doesn't end with a `\vec{b}`, it can only be called when
the stack has the right number of arguments

for sequences `e1 e2` a _sequence unification_ algorithm checks that the
stack produced by `e1` matches the stack expected by `e2`

> W: I want to put in a small plug for myself ...
> K: yes, this is very related to row polymorphism


### Current Research

Q. can we remove the restriction that sequences `\vec{b}` only appear at
   the end of a type?

I've been investigating this, by the way made a `#lang` for unification
in this language.

> W: out of curiosity, why make a `#lang`?
> M: the racket doctrine exists, and it is so easy to make a language that
>    you just do so without thinking about it
> W: I haven't drunk that last bit of kool-aid yet
> K: parsing & unparsing were the big wins


> M: to all, you can think that something's useless --- I even say it sometimes
>    --- but do not believe that its useless

- - -

(addendum by Gabriel)

If you were intrigued by the PL aspects of stack languages as presented in
Rob's HOPL talk, you may be interested in

- http://yosefk.com/blog/my-history-with-forth-stack-machines.html

It's a nice (long, old) blog post about a small, wonderful, weird community of
Forth programmer, that has somehow grow in parallel to our small, wonderful,
weird communities of functional (meta)programmers or scripters or whatever.

Forth is not, however, representative of modern concatenative languages. For
this, you should look at Factor, which is Actually Usable,

- https://factorcode.org/

The Re-Factor blog has plenty of cute small examples of Factor code:

- http://re-factor.blogspot.com/
