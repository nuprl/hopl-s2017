# Title: Tracing JITs for Dynamic Languages
## Speaker: Ming-Ho Yee

The plan today is to go over 5 papers:

- Bala, Duesterwald, and Banerjia. _Dynamo: a transparent dynamic optimization system_. PLDI 2000
- Gal and Franz. _Incremental dynamic code generation with trace trees._ UC Irvine Tech Report, 2006.
- Gal, Eich, Shaver, Anderson, Mandelin, Haghighat, Kaplan, Hoare, Zbarsky,
  Orendorff, Ruderman, Smith, Reitmaier, Bebenita, Chang, and Franz.
  _Trace-based just-in-time type specialization for dynamic languages_. PLDI
  2009.
- Bolz, Cuni, Fijałkowski, and Rigo. _Tracing the meta-level: PyPy’s tracing JIT compiler_. ICOOOLPS 2009.
- Ardö, Bolz, and Fijałkowski. _Loop-aware optimizations in PyPy’s tracing JIT_. DLS 2012.

Links (maybe paywalled) here:

- [http://www.ccs.neu.edu/home/matthias/7480-s17/Summary___Materials.html#%28part._mhy1%29](http://www.ccs.neu.edu/home/matthias/7480-s17/Summary___Materials.html#%28part._mhy1%29)

The [LuaJit](http://luajit.org/) project has been a big innovator in this space.
The group doesn't publish papers, but they're very influential. (LuaJit has been
around since at least 2005; not sure when it became a tracing JIT.)


### Dynamo, PLDI 2000

`(1)` they implement an interpreter for machine code. The interpreter identifies
hot traces --- typically loops.

> M: does the programmer need to write annotations?
> H: no, the interpreter just monitors programs
> M: so if I have a loop and call out to another function --- things you can do
>    with λ spaghetti code 
> H: yes

> W: you said "interpret". What's the language?
> H: machine code

`(2)` the interpreter records a trace, optimizes it, and generates what's called
a _fragment_.

> M: fragment?
> H: more efficient machine code, fewer jumps

`(3)` traces are keyed by some condition in the machine code. After generating
a fragment, execute it on the hardware next time the condition is met.

> L: those instructions you drew on the boards --- you're assuming that's the
>    layout?
> D: machine code is the input to the interpreter (you can basically pick the
>    layout)


The "fast path" code looks like this (from left-to-right):

```
  +-----------------------------+-----------+
  | fast code . . .             | slow code |
  +-----------------------------+-----------+
```

with frequently-executed instructions all in a sequence.
(The tracing JIT picks the sequence when it generates the fragment.)
Some of the fast instructions are conditional jumps. These jumps go to
the slow path, but the key is, they're taken less often than the fall-throughs.

(Ming-Ho showed some graphs comparing Dynamo's performance on some HP-compiled
 C code vs. native execution and native-with-profile-guided-optimizations)

> M: these differences are not very big. I'm assuming this was before that
>    paper that showed O3 optimizations were "within the noise"?

(Perhaps: https://people.cs.umass.edu/~emery/pubs/stabilizer-asplos13.pdf)

> J: first, this is a bad graph. The y-axis is in seconds.
> (shocked surprise from the crowd)
> J: nowadays you would see normalized graphs
> M: but still, the difference is not that big
> J: this is ~20%. The noise papers were more like 3%.

> L: did they talk about how Dynamo is no better than the state of the art?
>    Native+PGO is better than Dynamo+PGO
> J: well nobody was using PGOs in practice
> H: people didn't use higher optimization levels either, for instance O4
>    loses your debugging info
> J: does their system maintain debugging info?
> H: ok bad example ...

> M: did anyone ever look at tracing on the λ level, in terms of the number
>    of beta reductions? Could see if this is generally a good idea.


### Trace Trees, Tech Report 2006

Other tracing methods require a CFG, which entails considerable overhead.
The idea with trace trees is to construct the CFG on-the-fly.
The authors claim this technique would be useful in embedded devices or other
resource-limited environments.

They also store the trees (somewhere) and do some sharing

1. find an anchor node --- the target of a backwards branch
2. count the number of times the anchor is hit, until it reaches a threshold
3. start recording a trace from the anchor
  - stop if you hit a cycle
  - stop if the trace gets too long
4. compile recorded trace to native code

Steps 1 and 2 are on Jav bytecode.

(store the traces somehow)

> L: would OS developers be upset with this behavior?
> D: it's 2006
> M: Racket does things like this today, let them complain :)
> H: yeah, who cares about stack randomization

Step 5: extend existing trace trees with new branches
Dynamo would always make new fragments. No sharing.
Trace trees can share a common prefix, but always have uncommon suffixes

> L: what about program size?
> M: potentially exponential
> M: do they count the number of dupicates in a tree? the width of a trace?

One issue is nested loops. An inner loop is a likely anchor due to being
executed so frequently. But a trace starting from an anchor that spins
around the outer loop before cycling can easily build a long suffix.
It's a common pathology.

(Graphs for trace trees. Conclusions:

- execution time was slower than Hotspot
- build compile time was faster than Hotspot
- and they generated 30x less code (wow !!!)
- and used 7x less memory


### Trace Monkey, PLDI 2006

Trace Monkey is for JavaScript. New challenges! JavaScript is a dynamic language.

> J: dynamic? We were just looking at Java, and now you say JavaScript is
>    dynamic. But Java has reflection and objects created at runtime --- all
>    that is possible and commonly used. So what do you mean by dynamic?
> H: no static type information, and the past work on tracing ignored reflection

> M: everyone knows reflection is hard to handle, e.g. Wand's _The Theory of
>    FEXPRS is trivial_

- http://www.ccs.neu.edu/home/wand/papers/fexprs.ps

> M: it would be interesting to know the minimal conditions for a trivial theory
> B: the FEXPRs paper just uses syntactic equality. That's it.
> X: "what is the code"
> J: ah so FEXPRs is no worse than R

(The "theory" in the paper is contextual equivalence. Given terms M1 and M2,
 one context that distinguishes them is a context that diverges if its argument
 is α-equivalent to M1. So contextual equivalence is trivial because it's only
 α-equivalence.)

The authors say: "yes JavaScript is dynamic, but we expect types to stabilize".
More or less.

> W: what do types mean here?
> H: Strings, numbers. Simple types that can be unboxed. The biggest success
>    is from unboxing numbers.

They keep a type map, use that to identify anchor points.

> M: what's the type of the type map?
> H: variables -> types

Types at the start and end of a trace need to match.

> J: in practice, this happens all the time in generic code
> A: you mean, ad-hoc polymorphic code

> M: so this was in spider monkey?
> H: it was
> M: do you know which of the 3 tiers of the compiler it was in?
> H: no

> O: this is on-the-fly monomorphization
>    It's just abstract interpretation. In honor of my friend Patrick,
>    I'm going to say this 2x a week for the rest of the semester.

Graphs.
Spider Monkey is faster on 9 of the 26 Octane benchmarks.
Have problems with C functions, recursion, regular expressions.
Makes sense.

> J: about these benchmarks, notice they have NOTHING to do with web programming
>    we have crypto, ray tracing, recursive contexts, addition, bitshifting,
>    silly numeric programs that have been around since the 60s
>
>    Tracing JITs did not help on real web code. Mozilla eventually took
>    tracing out of the compiler. Our hypothesis is that there isn't enough
>    stability in real web code.

Jan's paper on the subject:

- [http://janvitek.org/pubs/pldi10a.pdf](http://janvitek.org/pubs/pldi10a.pdf)

> M: if you find a paper like Jan's while doing your reading, please tell us!
>    Dead ends in research are very interesting, and rarely mentioned.
>    The important thing to ask is, "is this a real dead end, or can we take a
>    new approach?"

> J: tracing is not dead, JavaScript just isn't the right context
> H: yes, seems much better in Lua or PyPy

> M: the Lua community is ... different. Rodrigo doesn't cultivate papers.
>    and it's a small language, anyone can improve it, and they do.
> W: kinda like Scheme before R4
> M: are you an old man
> W: what's that? speak up


### PyPy

Interpreter for dynamic languages.
Trace a user-written interpreter that executes code for some language.

> W: "PyPy", is it related to Python?
> H: yes, RPython. PyPy is implemented in the RPython subset of Python,
>    and the original idea was to implement Python in RPython.
> M: Sam used PyPy to implement Pycket, basically implementing the CEK machine
>    in RPython. Got extremely good performance for the subset of the language
>    they implemented.

Pycket resources:

- [ICFP 2015 paper](http://homes.soic.indiana.edu/samth/pycket-draft.pdf)
- [GitHub](https://github.com/pycket/pycket)

If you email Sam or Spenser, they may have more recent updates.

In PyPy, anchor points are keyed by an interpreter PC and a "client program" PC.

The interpreter-writer does need to explicitly mark anchor points.

> J: seems they are very good for loops, what about recursion?
> M: there are old techniques for turning recursive programs into loops.
>    See Reynolds '73.
> G: also the Pycket paper

Graphs.
PyPy beats CPython

> J: remember, CPython is interpreted (it's a very low bar)

> J: on the subject, we made a bytecode interpeter for R
>    and it's slower than interpreting ASTs! There's enough
>    code generation --- small things --- in the programs we found that AST
>    interpreting is good enoug


### Loop Aware, DLS 2012

This next idea is due to the Lua team, but published by a different group.
Someone posted to the Lua mailing list, encouraged researchers to look at the
code or contact him to learn more. Kings College did, and brought the technique
to a broader audience. The Lua guy is in the acknowledgments.

> ?: should the Lua guy be an author?
> M: has anyone here heard of Schoenfinkel?
>    okay a few hands, well.
>    Schoenfinkel gave a talk, and someone in the audience took excellent notes,
>    turned those into the paper, and published it under Schoenfinkel's name.
>    THAT is how you give someone credit.

- - -

> J: one thing they don't say, tracing needs maybe 100s of iterations to warm
>    up. This is a little iffy.
> M: that's a point in favor of Pycket, it's okay to run the interpreter 100s
>    of times, then interpreted programs benefit.
> J: There's no methodology for the warmup. Obviously don't want to measure
>    the first run because that's just going to measure the compile times.
>    That cost amortizes. But maybe after the first 100 it's not at a steady
>    state.
> L: has anyone measured warmup time?
> J: yes, Kings College!

- [arXiv pdf](https://arxiv.org/pdf/1602.00602.pdf)
- [ICOOOLPS slides](http://soft-dev.org/talks/2016/warmup_icooolps16.pdf)

